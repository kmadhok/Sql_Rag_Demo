# SQL RAG Application - Environment Configuration Template
# Copy this file to .env and configure your API keys and settings

# ===== REQUIRED API KEYS =====

# OpenAI API Key (Primary embedding provider - Recommended for production)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Google Gemini API Key (Required for chat functionality)
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# ===== EMBEDDING CONFIGURATION =====

# Embedding Provider Selection
# Options: "openai" (recommended for production/Cloud Run) or "ollama" (local development)
EMBEDDINGS_PROVIDER=openai

# OpenAI Embedding Model Selection (if using OpenAI provider)
# Options:
# - text-embedding-3-small (1536 dims, $0.00002/1K tokens) - Cost-effective, recommended
# - text-embedding-3-large (3072 dims, $0.00013/1K tokens) - Higher quality, more expensive
# - text-embedding-ada-002 (1536 dims, $0.00010/1K tokens) - Legacy model
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ===== DEPLOYMENT ENVIRONMENT =====
# Set to "development" for local development or "production" for Cloud Run
ENVIRONMENT=development

# ===== OPTIONAL: OLLAMA CONFIGURATION =====
# Only needed if you set EMBEDDINGS_PROVIDER=ollama (not recommended for Cloud Run)
# Ollama Embedding Model (for local development only)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Ollama Service URL (for local development)
OLLAMA_BASE_URL=http://localhost:11434

# ===== STREAMLIT CONFIGURATION =====
# Streamlit server settings (automatically optimized per environment)
STREAMLIT_SERVER_ENABLE_CORS=false
STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION=false

# ===== PERFORMANCE TUNING =====
# Embedding generation timeout
EMBEDDING_TIMEOUT_SECONDS=30

# FAISS configuration
FAISS_ALLOW_DANGEROUS_DESERIALIZATION=true

# Vector store batch size
VECTOR_STORE_BATCH_SIZE=100

# ===== OPTIONAL: LOGGING AND DEBUGGING =====
# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Enable verbose logging for troubleshooting
# VERBOSE_LOGGING=true

# Enable debug mode for development
# DEBUG=true

# ===== OPTIONAL: FEATURE FLAGS =====
# Enable/disable specific features
ENABLE_ANALYTICS_CACHE=true
ENABLE_HYBRID_SEARCH=true
ENABLE_QUERY_REWRITING=true
ENABLE_SCHEMA_INJECTION=true
ENABLE_CHAT_INTERFACE=true

# ===== OPTIONAL: CACHE CONFIGURATION =====
# Query cache settings
ENABLE_QUERY_CACHE=true
CACHE_TTL_SECONDS=3600
MAX_CACHE_SIZE_MB=100

# ===== CLOUD RUN SPECIFIC (for production deployment) =====
# These settings are optimized for Google Cloud Run deployment
# Leave commented for local development

# Google Cloud Project ID (set automatically in Cloud Run)
# GOOGLE_CLOUD_PROJECT_ID=your-project-id

# Enable Google Cloud logging and monitoring
# ENABLE_CLOUD_LOGGING=true
# ENABLE_CLOUD_MONITORING=true

# ===== SECURITY SETTINGS =====
# API key validation (recommended for production)
ENABLE_API_KEY_VALIDATION=true

# Maximum request size (MB)
MAX_REQUEST_SIZE_MB=10

# ===== QUICK START INSTRUCTIONS =====
# 1. Copy this file to .env: cp .env.example .env
# 2. Get OpenAI API key: https://platform.openai.com/api-keys
# 3. Get Gemini API key: https://makersuite.google.com/app/apikey
# 4. Replace the placeholder values above with your actual API keys
# 5. Run: python data/standalone_embedding_generator.py --csv "sample_queries_with_metadata.csv"
# 6. Run: streamlit run app.py